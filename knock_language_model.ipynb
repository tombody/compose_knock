{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knock Knock Joke Generator\n",
    "## Team Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the training and validation paths\n",
    "TEST_PATH = 'test/'\n",
    "TRAIN_PATH = 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\r\n"
     ]
    }
   ],
   "source": [
    "# Number of test examples\n",
    "! ls -l {TEST_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\r\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "!ls -l {TRAIN_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_100.txt',\n",
       " 'train_101.txt',\n",
       " 'train_102.txt',\n",
       " 'train_104.txt',\n",
       " 'train_105.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating lists of training and test examples\n",
    "train_files = !ls {TRAIN_PATH}\n",
    "test_files = !ls {TEST_PATH}\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"knock, knock. who's there! arfur! arfur who? arfur got!\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first training examples together\n",
    "train_file = !cat {TRAIN_PATH}{train_files[0]}\n",
    "train_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the torchtext field.\n",
    "\n",
    "#required so that the tokenizer works\n",
    "spacy.load('en') \n",
    "TEXT = data.Field(lower=True, tokenize='spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs is the number of batches that the data gets split into\n",
    "# bptt is the number of words from each batch\n",
    "bs = 16\n",
    "bptt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'train/', 'validation': 'test/', 'test': 'test/'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = dict(train=TRAIN_PATH, validation=TEST_PATH, test=TEST_PATH)\n",
    "FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_data = LanguageModelData.from_text_files(\"\", TEXT, **FILES, bs=bs, bptt=bptt, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of batches\n",
    "len(model_data.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1181"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of vocab tokens\n",
    "model_data.nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '!', 'knock', 'who', '?', '.', ',', 'there', '<eos>']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of the words that have been tokenized\n",
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_vector_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_activations_per_layer = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_function = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = model_data.get_model(optimization_function, \n",
    "                               embedding_matrix_vector_size,\n",
    "                               hidden_activations_per_layer,\n",
    "                               number_of_layers,\n",
    "                               dropouti=0.05, \n",
    "                               dropout=0.05, \n",
    "                               wdrop=0.1, \n",
    "                               dropoute=0.02, \n",
    "                               dropouth=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This clips the learning rate\n",
    "learner.clip=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355dd206d0d44fa6b11346e6e1d28bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      5.71224    5.144524  \n",
      "    1      4.932596   4.472719                            \n",
      "    2      4.393734   4.211653                            \n",
      "    3      4.004725   3.970533                            \n",
      "    4      3.707027   3.732093                            \n",
      "    5      3.470103   3.746384                            \n",
      "    6      3.32136    3.645633                            \n",
      "    7      3.255934   3.543715                            \n",
      "    8      3.122264   3.359014                            \n",
      "    9      2.980833   3.295523                            \n",
      "    10     2.889807   3.284526                            \n",
      "    11     2.80832    3.246338                            \n",
      "    12     2.751825   3.307751                            \n",
      "    13     2.70912    3.243693                            \n",
      "    14     2.675303   3.255986                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.2559863062929515]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca77265cd684e5c82fe1002d8451760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      2.856145   3.139025  \n",
      "    1      2.713763   3.167377                            \n",
      "    2      2.569897   3.38607                             \n",
      "    3      2.422053   3.432718                            \n",
      "    4      2.264729   3.513473                            \n",
      "    5      2.11268    3.656592                            \n",
      "    6      2.007501   3.596226                            \n",
      "    7      1.915398   3.566329                            \n",
      "    8      1.886388   3.566361                            \n",
      "    9      1.840334   3.536302                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.536302279253475]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = \"who\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [TEXT.tokenize(ss)]\n",
    "t = TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].bs = 1\n",
    "model.eval()\n",
    "model.reset()\n",
    "res, *_ = model(t)\n",
    "model[0].bs = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?', '!', 'you', 'there', 'is', \"'s\", 'â€™s', 'the', '\"', 'your']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(next_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who \n",
      "\n",
      "? <eos> knock , knock . who 's there ! ben ! ben who ? carrie - n of the door ! <eos> knock , knock . who 's there ! ben ! ben who ? carrie - n of the door ! <eos> knock , knock . who 's there ! ben ! ben who ? carrie - n of the door ! <eos> knock , knock . who 's there ! ben ! ben who ? carrie - n of the door ! <eos> knock , knock . who 's there ! ben ! ben who ? carrie ...\n"
     ]
    }
   ],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(100):\n",
    "    n=res[-1].topk(2)[1]\n",
    "    n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = model(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
